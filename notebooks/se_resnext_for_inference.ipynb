{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from pathlib import Path\n",
    "import skimage.io\n",
    "import cv2\n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "\n",
    "from functools import partial\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.utils import model_zoo\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "import albumentations as album"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EasyDict(dict):\n",
    "    \"\"\"\n",
    "    Get attributes\n",
    "    >>> d = EasyDict({'foo':3})\n",
    "    >>> d['foo']\n",
    "    3\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    AttributeError: 'EasyDict' object has no attribute 'bar'\n",
    "    Works recursively\n",
    "    >>> d = EasyDict({'foo':3, 'bar':{'x':1, 'y':2}})\n",
    "    >>> isinstance(d.bar, dict)\n",
    "    True\n",
    "    >>> d.bar.x\n",
    "    1\n",
    "    Bullet-proof\n",
    "    >>> EasyDict({})\n",
    "    {}\n",
    "    >>> EasyDict(d={})\n",
    "    {}\n",
    "    >>> EasyDict(None)\n",
    "    {}\n",
    "    >>> d = {'a': 1}\n",
    "    >>> EasyDict(**d)\n",
    "    {'a': 1}\n",
    "    Set attributes\n",
    "    >>> d = EasyDict()\n",
    "    >>> d.foo = 3\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar = {'prop': 'value'}\n",
    "    >>> d.bar.prop\n",
    "    'value'\n",
    "    >>> d\n",
    "    {'foo': 3, 'bar': {'prop': 'value'}}\n",
    "    >>> d.bar.prop = 'newer'\n",
    "    >>> d.bar.prop\n",
    "    'newer'\n",
    "    Values extraction\n",
    "    >>> d = EasyDict({'foo':0, 'bar':[{'x':1, 'y':2}, {'x':3, 'y':4}]})\n",
    "    >>> isinstance(d.bar, list)\n",
    "    True\n",
    "    >>> from operator import attrgetter\n",
    "    >>> map(attrgetter('x'), d.bar)\n",
    "    [1, 3]\n",
    "    >>> map(attrgetter('y'), d.bar)\n",
    "    [2, 4]\n",
    "    >>> d = EasyDict()\n",
    "    >>> d.keys()\n",
    "    []\n",
    "    >>> d = EasyDict(foo=3, bar=dict(x=1, y=2))\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar.x\n",
    "    1\n",
    "    Still like a dict though\n",
    "    >>> o = EasyDict({'clean':True})\n",
    "    >>> o.items()\n",
    "    [('clean', True)]\n",
    "    And like a class\n",
    "    >>> class Flower(EasyDict):\n",
    "    ...     power = 1\n",
    "    ...\n",
    "    >>> f = Flower()\n",
    "    >>> f.power\n",
    "    1\n",
    "    >>> f = Flower({'height': 12})\n",
    "    >>> f.height\n",
    "    12\n",
    "    >>> f['power']\n",
    "    1\n",
    "    >>> sorted(f.keys())\n",
    "    ['height', 'power']\n",
    "    update and pop items\n",
    "    >>> d = EasyDict(a=1, b='2')\n",
    "    >>> e = EasyDict(c=3.0, a=9.0)\n",
    "    >>> d.update(e)\n",
    "    >>> d.c\n",
    "    3.0\n",
    "    >>> d['c']\n",
    "    3.0\n",
    "    >>> d.get('c')\n",
    "    3.0\n",
    "    >>> d.update(a=4, b=4)\n",
    "    >>> d.b\n",
    "    4\n",
    "    >>> d.pop('a')\n",
    "    4\n",
    "    >>> d.a\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    AttributeError: 'EasyDict' object has no attribute 'a'\n",
    "    \"\"\"\n",
    "    def __init__(self, d=None, **kwargs):\n",
    "        if d is None:\n",
    "            d = {}\n",
    "        if kwargs:\n",
    "            d.update(**kwargs)\n",
    "        for k, v in d.items():\n",
    "            setattr(self, k, v)\n",
    "        # Class attributes\n",
    "        for k in self.__class__.__dict__.keys():\n",
    "            if not (k.startswith('__') and k.endswith('__')) and not k in ('update', 'pop'):\n",
    "                setattr(self, k, getattr(self, k))\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, (list, tuple)):\n",
    "            value = [self.__class__(x)\n",
    "                     if isinstance(x, dict) else x for x in value]\n",
    "        elif isinstance(value, dict) and not isinstance(value, self.__class__):\n",
    "            value = self.__class__(value)\n",
    "        super(EasyDict, self).__setattr__(name, value)\n",
    "        super(EasyDict, self).__setitem__(name, value)\n",
    "\n",
    "    __setitem__ = __setattr__\n",
    "\n",
    "    def update(self, e=None, **f):\n",
    "        d = e or dict()\n",
    "        d.update(f)\n",
    "        for k in d:\n",
    "            setattr(self, k, d[k])\n",
    "\n",
    "    def pop(self, k, d=None):\n",
    "        delattr(self, k)\n",
    "        return super(EasyDict, self).pop(k, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(cfg):\n",
    "    def get_object(transform):\n",
    "        if hasattr(album, transform.name):\n",
    "            return getattr(album, transform.name)\n",
    "        else:\n",
    "            return eval(transform.name)\n",
    "    if cfg['transforms']:\n",
    "        transforms = [get_object(transform)(**transform.params) for name, transform in cfg['transforms'].items()]\n",
    "        return album.Compose(transforms)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def concat_tiles(image_list, seed):\n",
    "    image = []\n",
    "    row_num = int(np.sqrt(len(image_list)))\n",
    "\n",
    "    for i in range(row_num):\n",
    "        v = [image_list[(row_num * i) + j] for j in range(row_num)]\n",
    "        image.append(cv2.vconcat(v))\n",
    "\n",
    "    return cv2.hconcat(image)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, labels, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.image_ids = df['image_id'].values\n",
    "        self.labels = labels\n",
    "        self.transforms = get_transforms(self.cfg)\n",
    "        self.is_train = cfg.is_train\n",
    "        self.img_type = cfg.img_type\n",
    "        if self.img_type == 'image':\n",
    "            self.image_path = '/kaggle/test_images'\n",
    "        elif self.img_type == 'tile':\n",
    "            self.image_path = '/kaggle/test_tile_images'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        if self.img_type == 'image':\n",
    "            image = cv2.imread(f'{self.image_path}/{image_id}.png')\n",
    "        elif self.img_type == 'tile':\n",
    "            tiles = []\n",
    "            for i in range(16):\n",
    "                tiles.append(cv2.imread(f'{self.image_path}/{image_id}_{i}.png'))\n",
    "            image = concat_tiles(tiles, idx)\n",
    "        image = 255 - (image * (255.0/image.max())).astype(np.uint8)\n",
    "        image = cv2.resize(image, dsize=(self.cfg.img_size.height, self.cfg.img_size.width))\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        image = image.transpose(2, 0, 1).astype(np.float32)\n",
    "\n",
    "        if self.is_train:\n",
    "            label = self.labels.values[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, x.shape[2:])\n",
    "\n",
    "\n",
    "class MaxPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.max_pool2d(x, x.shape[2:])\n",
    "\n",
    "\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/c/bengaliai-cv19/discussion/123432\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "    \n",
    "    \n",
    "layer_encoder = {\n",
    "    'AvgPool': AvgPool,\n",
    "    'MaxPool': MaxPool,\n",
    "    'AdaptiveConcatPool2d': AdaptiveConcatPool2d,\n",
    "    'GeM': GeM,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Regression\n",
    "# =============================================================================\n",
    "class MSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return self.mse(yhat,y)\n",
    "\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Classification\n",
    "# =============================================================================\n",
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.xloss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return self.xloss(yhat,y)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/55681502/label-smoothing-in-pytorch\n",
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth_one_hot(targets:torch.Tensor, n_classes:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = torch.empty(size=(targets.size(0), n_classes),\n",
    "                    device=targets.device) \\\n",
    "                .fill_(smoothing /(n_classes-1)) \\\n",
    "                .scatter_(1, targets.data.unsqueeze(1), 1.-smoothing)\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss._smooth_one_hot(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        lsm = F.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            lsm = lsm * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = -(targets * lsm).sum(-1)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "# https://kyudy.hatenablog.com/entry/2019/05/20/105526\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, eps=1e-7):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        logit = F.softmax(input, dim=1)\n",
    "        logit = logit.clamp(self.eps, 1. - self.eps)\n",
    "        logit_ls = torch.log(logit)\n",
    "        loss = F.nll_loss(logit_ls, target, reduction=\"none\")\n",
    "        view = target.size() + (1,)\n",
    "        index = target.view(*view)\n",
    "        loss = loss * (1 - logit.gather(1, index).squeeze(1)) ** self.gamma # focal loss\n",
    "\n",
    "        return loss.sum()\n",
    "\n",
    "\n",
    "# https://github.com/vandit15/Class-balanced-loss-pytorch/blob/master/class_balanced_loss.py\n",
    "def focal_loss(labels, logits, alpha, gamma):\n",
    "    \"\"\"Compute the focal loss between `logits` and the ground truth `labels`.\n",
    "    Focal loss = -alpha_t * (1-pt)^gamma * log(pt)\n",
    "    where pt is the probability of being classified to the true class.\n",
    "    pt = p (if true class), otherwise pt = 1 - p. p = sigmoid(logit).\n",
    "    Args:\n",
    "      labels: A float tensor of size [batch, num_classes].\n",
    "      logits: A float tensor of size [batch, num_classes].\n",
    "      alpha: A float tensor of size [batch_size]\n",
    "        specifying per-example weight for balanced cross entropy.\n",
    "      gamma: A float scalar modulating loss from hard and easy examples.\n",
    "    Returns:\n",
    "      focal_loss: A float32 scalar representing normalized total loss.\n",
    "    \"\"\"    \n",
    "    BCLoss = F.binary_cross_entropy_with_logits(input = logits, target = labels,reduction = \"none\")\n",
    "\n",
    "    if gamma == 0.0:\n",
    "        modulator = 1.0\n",
    "    else:\n",
    "        modulator = torch.exp(-gamma * labels * logits - gamma * torch.log(1 + \n",
    "            torch.exp(-1.0 * logits)))\n",
    "\n",
    "    loss = modulator * BCLoss\n",
    "\n",
    "    weighted_loss = alpha * loss\n",
    "    focal_loss = torch.sum(weighted_loss)\n",
    "\n",
    "    focal_loss /= torch.sum(labels)\n",
    "    return focal_loss\n",
    "\n",
    "\n",
    "class ClassBalancedLoss(nn.Module):\n",
    "    def __init__(self, samples_per_cls, no_of_classes, loss_type, beta, gamma):\n",
    "        \"\"\"Compute the Class Balanced Loss between `logits` and the ground truth `labels`.\n",
    "        Class Balanced Loss: ((1-beta)/(1-beta^n))*Loss(labels, logits)\n",
    "        where Loss is one of the standard losses used for Neural Networks.\n",
    "        Args:\n",
    "        labels: A int tensor of size [batch].\n",
    "        logits: A float tensor of size [batch, no_of_classes].\n",
    "        samples_per_cls: A python list of size [no_of_classes].\n",
    "        no_of_classes: total number of classes. int\n",
    "        loss_type: string. One of \"sigmoid\", \"focal\", \"softmax\".\n",
    "        beta: float. Hyperparameter for Class balanced loss.\n",
    "        gamma: float. Hyperparameter for Focal loss.\n",
    "        Returns:\n",
    "        cb_loss: A float tensor representing class balanced loss\n",
    "        \"\"\"\n",
    "        super(ClassBalancedLoss, self).__init__()\n",
    "        self.samples_per_cls = samples_per_cls\n",
    "        self.no_of_classes = no_of_classes\n",
    "        self.loss_type = loss_type\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        effective_num = 1.0 - torch.pow(self.beta, self.samples_per_cls)\n",
    "        weights = (1.0 - self.beta) / torch.tensor(effective_num)\n",
    "        weights = weights / torch.sum(weights) * self.no_of_classes\n",
    "\n",
    "        labels_one_hot = F.one_hot(labels, self.no_of_classes).float()\n",
    "\n",
    "        weights = torch.tensor(weights).float()\n",
    "        weights = weights.unsqueeze(0)\n",
    "        weights = weights.repeat(labels_one_hot.shape[0],1) * labels_one_hot\n",
    "        weights = weights.sum(1)\n",
    "        weights = weights.unsqueeze(1)\n",
    "        weights = weights.repeat(1,self.no_of_classes)\n",
    "\n",
    "        if self.loss_type == \"focal\":\n",
    "            cb_loss = focal_loss(labels_one_hot, logits, weights, self.gamma)\n",
    "        elif self.loss_type == \"sigmoid\":\n",
    "            cb_loss = F.binary_cross_entropy_with_logits(input = logits,target = labels_one_hot, weights = weights)\n",
    "        elif self.loss_type == \"softmax\":\n",
    "            pred = logits.softmax(dim = 1)\n",
    "            cb_loss = F.binary_cross_entropy(input = pred, target = labels_one_hot, weight = weights)\n",
    "        return cb_loss\n",
    "\n",
    "\n",
    "class OhemLoss(nn.Module):\n",
    "    def __init__(self, rate=0.8):\n",
    "        super(OhemLoss, self).__init__()\n",
    "        self.rate = rate\n",
    "\n",
    "    def update_rate(self, rate):\n",
    "        self.rate = rate\n",
    "        \n",
    "    def forward(self, cls_pred, cls_target):\n",
    "        batch_size = cls_pred.size(0) \n",
    "        ohem_cls_loss = F.cross_entropy(cls_pred, cls_target, reduction='none', ignore_index=-1)\n",
    "\n",
    "        sorted_ohem_loss, idx = torch.sort(ohem_cls_loss, descending=True)\n",
    "        keep_num = min(sorted_ohem_loss.size()[0], int(batch_size*self.rate) )\n",
    "        if keep_num < sorted_ohem_loss.size()[0]:\n",
    "            keep_idx_cuda = idx[:keep_num]\n",
    "            ohem_cls_loss = ohem_cls_loss[keep_idx_cuda]\n",
    "        cls_loss = ohem_cls_loss.sum() / keep_num\n",
    "        return cls_loss\n",
    "    \n",
    "    \n",
    "loss_encoder = {\n",
    "    'MSELoss': MSELoss,\n",
    "    'RMSELoss': RMSELoss,\n",
    "    'CrossEntropyLoss': CrossEntropyLoss,\n",
    "    'SmoothCrossEntropyLoss': SmoothCrossEntropyLoss,\n",
    "    'FocalLoss': FocalLoss,\n",
    "    'ClassBalancedLoss': ClassBalancedLoss,\n",
    "    'OhemLoss': OhemLoss\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_settings = {\n",
    "    'se_resnext50_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext101_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "# Source: https://github.com/Cadene/pretrained-models.pytorch/blob/master/pretrainedmodels/models/senet.py\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "    \n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class SEBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    Bottleneck for SENet154.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
    "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
    "    (the latter is used in the torchvision implementation of ResNet).\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
    "                               stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
    "                               groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "        \n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        block (nn.Module): Bottleneck class.\n",
    "            - For SENet154: SEBottleneck\n",
    "            - For SE-ResNet models: SEResNetBottleneck\n",
    "            - For SE-ResNeXt models:  SEResNeXtBottleneck\n",
    "        layers (list of ints): Number of residual blocks for 4 layers of the\n",
    "            network (layer1...layer4).\n",
    "        groups (int): Number of groups for the 3x3 convolution in each\n",
    "            bottleneck block.\n",
    "            - For SENet154: 64\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models:  32\n",
    "        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n",
    "            - For all models: 16\n",
    "        dropout_p (float or None): Drop probability for the Dropout layer.\n",
    "            If `None` the Dropout layer is not used.\n",
    "            - For SENet154: 0.2\n",
    "            - For SE-ResNet models: None\n",
    "            - For SE-ResNeXt models: None\n",
    "        inplanes (int):  Number of input channels for layer1.\n",
    "            - For SENet154: 128\n",
    "            - For SE-ResNet models: 64\n",
    "            - For SE-ResNeXt models: 64\n",
    "        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n",
    "            a single 7x7 convolution in layer0.\n",
    "            - For SENet154: True\n",
    "            - For SE-ResNet models: False\n",
    "            - For SE-ResNeXt models: False\n",
    "        downsample_kernel_size (int): Kernel size for downsampling convolutions\n",
    "            in layer2, layer3 and layer4.\n",
    "            - For SENet154: 3\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models: 1\n",
    "        downsample_padding (int): Padding for downsampling convolutions in\n",
    "            layer2, layer3 and layer4.\n",
    "            - For SENet154: 1\n",
    "            - For SE-ResNet models: 0\n",
    "            - For SE-ResNeXt models: 0\n",
    "        num_classes (int): Number of outputs in `last_linear` layer.\n",
    "            - For all models: 1000\n",
    "        \"\"\"\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avg_pool = nn.AvgPool2d(7, stride=1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def initialize_pretrained_model(model, num_classes, settings):\n",
    "    assert num_classes == settings['num_classes'], \\\n",
    "        'num_classes should be {}, but is {}'.format(\n",
    "            settings['num_classes'], num_classes)\n",
    "    model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "    model.input_space = settings['input_space']\n",
    "    model.input_size = settings['input_size']\n",
    "    model.input_range = settings['input_range']\n",
    "    model.mean = settings['mean']\n",
    "    model.std = settings['std']\n",
    "\n",
    "\n",
    "def se_resnext50_32x4d(num_classes=1000, pretrained=True):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained:\n",
    "        settings = pretrained_settings['se_resnext50_32x4d']['imagenet']\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext101_32x4d(num_classes=1000, pretrained=False):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained:\n",
    "        settings = pretrained_settings['se_resnext101_32x4d']['imagenet']\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'se_resnext50_32x4d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e18e6dbb1df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_encoder = {\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m'se_resnext50_32x4d'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mse_resnext50_32x4d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'se_resnext101_32x4d'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mse_resnext101_32x4d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'se_resnext50_32x4d' is not defined"
     ]
    }
   ],
   "source": [
    "model_encoder = {\n",
    "    'se_resnext50_32x4d': se_resnext50_32x4d,\n",
    "    'se_resnext101_32x4d': se_resnext101_32x4d,\n",
    "}\n",
    "\n",
    "\n",
    "def set_channels(child, cfg):\n",
    "    if cfg.model.n_channels < 3:\n",
    "        child_weight = child.weight.data[:, :cfg.model.n_channels, :, :]\n",
    "    else:\n",
    "        child_weight = torch.cat([child.weight.data[:, :, :, :], child.weight.data[:, :int(cfg.model.n_channels - 3), :, :]], dim=1)\n",
    "    setattr(child, 'in_channels', cfg.model.n_channels)\n",
    "\n",
    "    if cfg.model.pretrained:\n",
    "        setattr(child.weight, 'data', child_weight)\n",
    "\n",
    "\n",
    "def replace_channels(model, cfg):\n",
    "    if cfg.model.name.startswith('densenet'):\n",
    "        set_channels(model.features[0], cfg)\n",
    "    elif cfg.model.name.startswith('efficientnet'):\n",
    "        set_channels(model._conv_stem, cfg)\n",
    "    elif cfg.model.name.startswith('mobilenet'):\n",
    "        set_channels(model.features[0][0], cfg)\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        set_channels(model.layer0.conv1, cfg)\n",
    "    elif cfg.model.name.startswith('resnet') or cfg.model.name.startswith('resnex') or cfg.model.name.startswith('wide_resnet'):\n",
    "        set_channels(model.conv1, cfg)\n",
    "    elif cfg.model.name.startswith('resnest'):\n",
    "        set_channels(model.conv1[0], cfg)\n",
    "\n",
    "\n",
    "def get_head(cfg):\n",
    "    head_modules = []\n",
    "    \n",
    "    for m in cfg.values():\n",
    "        module = getattr(nn, m['name'])(**m['params'])\n",
    "        head_modules.append(module)\n",
    "\n",
    "    head_modules = nn.Sequential(*head_modules)\n",
    "    \n",
    "    return head_modules\n",
    "\n",
    "\n",
    "def replace_fc(model, cfg):\n",
    "    if cfg.model.metric:\n",
    "        classes = 1000\n",
    "    else:\n",
    "        classes = cfg.model.n_classes\n",
    "\n",
    "    if cfg.model.name.startswith('densenet'):\n",
    "        model.classifier = get_head(cfg.model.head)\n",
    "    elif cfg.model.name.startswith('efficientnet'):\n",
    "        model._fc = get_head(cfg.model.head)\n",
    "    elif cfg.model.name.startswith('mobilenet'):\n",
    "        model.classifier[1] = get_head(cfg.model.head)\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        model.last_linear = get_head(cfg.model.head)\n",
    "    elif (cfg.model.name.startswith('resnet') or\n",
    "          cfg.model.name.startswith('resnex') or\n",
    "          cfg.model.name.startswith('wide_resnet') or\n",
    "          cfg.model.name.startswith('resnest')):\n",
    "        model.fc = get_head(cfg.model.head)\n",
    "    return model\n",
    "\n",
    "\n",
    "def replace_pool(model, cfg):\n",
    "    avgpool = layer_encoder[cfg.model.avgpool.name](**cfg.model.avgpool.params)\n",
    "    if cfg.model.name.startswith('efficientnet'):\n",
    "        model._avg_pooling = avgpool\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        model.avg_pool = avgpool\n",
    "    elif cfg.model.name.startswith('resnet') or cfg.model.name.startswith('resnex') or cfg.model.name.startswith('wide_resnet') or cfg.model.name.startswith('resnest'):\n",
    "        model.avgpool = avgpool\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(cfg):\n",
    "    model = model_encoder[cfg.model.name](pretrained=False)\n",
    "    if cfg.model.n_channels != 3:\n",
    "        replace_channels(model, cfg)\n",
    "    model = replace_fc(model, cfg)\n",
    "    if cfg.model.avgpool:\n",
    "        model = replace_pool(model, cfg)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_loss(cfg):\n",
    "    loss_ = layer_encoder[cfg.loss.name](**cfg.loss.params)\n",
    "    return loss_\n",
    "\n",
    "\n",
    "def get_dataloader(df, labels, cfg):\n",
    "    dataset = CustomDataset(df, labels, cfg)\n",
    "    loader = DataLoader(dataset, **cfg.loader)\n",
    "    return loader\n",
    "\n",
    "\n",
    "def get_optim(cfg, parameters):\n",
    "    optim = getattr(torch.optim, cfg.optimizer.name)(params=parameters, **cfg.optimizer.params)\n",
    "    return optim\n",
    "\n",
    "\n",
    "def get_scheduler(cfg, optimizer):\n",
    "    if cfg.scheduler.name == 'ReduceLROnPlateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            **cfg.scheduler.params,\n",
    "        )\n",
    "    else:\n",
    "        scheduler = getattr(torch.optim.lr_scheduler, cfg.scheduler.name)(\n",
    "            optimizer,\n",
    "            **cfg.scheduler.params,\n",
    "        )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(y_hat, y):\n",
    "    return cohen_kappa_score(y_hat, y, weights='quadratic')\n",
    "\n",
    "\n",
    "class QWKOptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            elif pred >= coef[3] and pred < coef[4]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 5\n",
    "\n",
    "        ll = quadratic_weighted_kappa(y, X_p)\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(df, data_dir, save_dir):\n",
    "    for img_id in df['image_id']:\n",
    "        load_path = f'{data_dir}/{img_id}.tiff'\n",
    "        save_path = f'{save_dir}/{img_id}.png'\n",
    "            \n",
    "        biopsy = skimage.io.MultiImage(load_path)\n",
    "        img = cv2.resize(biopsy[-1], (512, 512))\n",
    "        cv2.imwrite(save_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile(img, sz=128, N=16):\n",
    "    result = []\n",
    "    shape = img.shape\n",
    "    pad0, pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n",
    "    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],\n",
    "                constant_values=255)\n",
    "    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n",
    "    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n",
    "    if len(img) < N:\n",
    "        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n",
    "    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n",
    "    img = img[idxs]\n",
    "    for i in range(len(img)):\n",
    "        result.append({'img':img[i], 'idx':i})\n",
    "    return result\n",
    "\n",
    "def create_tile(df, data_dir, save_dir):\n",
    "    x_tot,x2_tot = [],[]\n",
    "    for img_id in df['image_id']:\n",
    "        load_path = f'{data_dir}/{img_id}.tiff'\n",
    "        \n",
    "        img = skimage.io.MultiImage(load_path)[-1]\n",
    "        tiles = tile(img)\n",
    "        for t in tiles:\n",
    "            img, idx = t['img'],t['idx']\n",
    "#             x_tot.append((img/255.0).reshape(-1,3).mean(0))\n",
    "#             x2_tot.append(((img/255.0)**2).reshape(-1,3).mean(0))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            save_path = f'{save_dir}/{img_id}_{idx}.png'\n",
    "            cv2.imwrite(save_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(sample, data_dir, log_path):\n",
    "    if os.path.exists(data_dir):\n",
    "        print('run inference')\n",
    "        \n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        test_loader = get_dataloader(test_df, labels=None, cfg=cfg.data.test)\n",
    "        model = get_model(cfg).to(device)\n",
    "        model.load_state_dict(torch.load(log_path / 'weight_best.pt'))\n",
    "\n",
    "        all_preds = []\n",
    "        model.eval()\n",
    "        for images in test_loader:\n",
    "            images = Variable(images).to(device)\n",
    "\n",
    "            preds = model(images.float())\n",
    "            all_preds.append(preds.cpu().detach().numpy())\n",
    "        \n",
    "        if cfg.model.n_classes > 1:\n",
    "            preds_label = np.concatenate(all_preds).argmax(1)\n",
    "        else:\n",
    "            optR = QWKOptimizedRounder()\n",
    "            best_coef = np.load(log_path / 'best_coef.npy')\n",
    "            preds_label = optR.predict(np.concatenate(all_preds.copy()), best_coef)\n",
    "\n",
    "        sample['isup_grade'] = preds_label.astype(int)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/kaggle/input/prostate-cancer-grade-assessment/')\n",
    "log_path = Path(glob.glob('/kaggle/input/sub-*')[0])\n",
    "\n",
    "with open(log_path / 'config.yml', 'r') as yf:\n",
    "    cfg = EasyDict(yaml.safe_load(yf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(root / 'test.csv')\n",
    "data_dir = '/kaggle/input/prostate-cancer-grade-assessment/test_images'\n",
    "save_dir = '/kaggle/test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    test_df = pd.read_csv(root / 'train.csv').iloc[:3]\n",
    "    data_dir = '/kaggle/input/prostate-cancer-grade-assessment/train_images'\n",
    "\n",
    "if cfg.data.train.img_type == 'image':\n",
    "    resize(test_df, data_dir, save_dir)\n",
    "elif cfg.data.train.img_type == 'tile':\n",
    "    save_dir = '/kaggle/test_tile_images'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    create_tile(test_df, data_dir, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(root / 'sample_submission.csv')\n",
    "sample_df = submit(sample_df, data_dir, log_path)\n",
    "sample_df.to_csv('submission.csv', index=False)\n",
    "sample_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
