{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from pathlib import Path\n",
    "import skimage.io\n",
    "import cv2\n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "\n",
    "from functools import partial\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.nn.modules.utils import _pair\n",
    "from torch.utils import model_zoo\n",
    "from torch.nn import Conv2d, Module, Linear, BatchNorm2d, ReLU\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "import albumentations as album"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EasyDict(dict):\n",
    "    \"\"\"\n",
    "    Get attributes\n",
    "    >>> d = EasyDict({'foo':3})\n",
    "    >>> d['foo']\n",
    "    3\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    AttributeError: 'EasyDict' object has no attribute 'bar'\n",
    "    Works recursively\n",
    "    >>> d = EasyDict({'foo':3, 'bar':{'x':1, 'y':2}})\n",
    "    >>> isinstance(d.bar, dict)\n",
    "    True\n",
    "    >>> d.bar.x\n",
    "    1\n",
    "    Bullet-proof\n",
    "    >>> EasyDict({})\n",
    "    {}\n",
    "    >>> EasyDict(d={})\n",
    "    {}\n",
    "    >>> EasyDict(None)\n",
    "    {}\n",
    "    >>> d = {'a': 1}\n",
    "    >>> EasyDict(**d)\n",
    "    {'a': 1}\n",
    "    Set attributes\n",
    "    >>> d = EasyDict()\n",
    "    >>> d.foo = 3\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar = {'prop': 'value'}\n",
    "    >>> d.bar.prop\n",
    "    'value'\n",
    "    >>> d\n",
    "    {'foo': 3, 'bar': {'prop': 'value'}}\n",
    "    >>> d.bar.prop = 'newer'\n",
    "    >>> d.bar.prop\n",
    "    'newer'\n",
    "    Values extraction\n",
    "    >>> d = EasyDict({'foo':0, 'bar':[{'x':1, 'y':2}, {'x':3, 'y':4}]})\n",
    "    >>> isinstance(d.bar, list)\n",
    "    True\n",
    "    >>> from operator import attrgetter\n",
    "    >>> map(attrgetter('x'), d.bar)\n",
    "    [1, 3]\n",
    "    >>> map(attrgetter('y'), d.bar)\n",
    "    [2, 4]\n",
    "    >>> d = EasyDict()\n",
    "    >>> d.keys()\n",
    "    []\n",
    "    >>> d = EasyDict(foo=3, bar=dict(x=1, y=2))\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar.x\n",
    "    1\n",
    "    Still like a dict though\n",
    "    >>> o = EasyDict({'clean':True})\n",
    "    >>> o.items()\n",
    "    [('clean', True)]\n",
    "    And like a class\n",
    "    >>> class Flower(EasyDict):\n",
    "    ...     power = 1\n",
    "    ...\n",
    "    >>> f = Flower()\n",
    "    >>> f.power\n",
    "    1\n",
    "    >>> f = Flower({'height': 12})\n",
    "    >>> f.height\n",
    "    12\n",
    "    >>> f['power']\n",
    "    1\n",
    "    >>> sorted(f.keys())\n",
    "    ['height', 'power']\n",
    "    update and pop items\n",
    "    >>> d = EasyDict(a=1, b='2')\n",
    "    >>> e = EasyDict(c=3.0, a=9.0)\n",
    "    >>> d.update(e)\n",
    "    >>> d.c\n",
    "    3.0\n",
    "    >>> d['c']\n",
    "    3.0\n",
    "    >>> d.get('c')\n",
    "    3.0\n",
    "    >>> d.update(a=4, b=4)\n",
    "    >>> d.b\n",
    "    4\n",
    "    >>> d.pop('a')\n",
    "    4\n",
    "    >>> d.a\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    AttributeError: 'EasyDict' object has no attribute 'a'\n",
    "    \"\"\"\n",
    "    def __init__(self, d=None, **kwargs):\n",
    "        if d is None:\n",
    "            d = {}\n",
    "        if kwargs:\n",
    "            d.update(**kwargs)\n",
    "        for k, v in d.items():\n",
    "            setattr(self, k, v)\n",
    "        # Class attributes\n",
    "        for k in self.__class__.__dict__.keys():\n",
    "            if not (k.startswith('__') and k.endswith('__')) and not k in ('update', 'pop'):\n",
    "                setattr(self, k, getattr(self, k))\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, (list, tuple)):\n",
    "            value = [self.__class__(x)\n",
    "                     if isinstance(x, dict) else x for x in value]\n",
    "        elif isinstance(value, dict) and not isinstance(value, self.__class__):\n",
    "            value = self.__class__(value)\n",
    "        super(EasyDict, self).__setattr__(name, value)\n",
    "        super(EasyDict, self).__setitem__(name, value)\n",
    "\n",
    "    __setitem__ = __setattr__\n",
    "\n",
    "    def update(self, e=None, **f):\n",
    "        d = e or dict()\n",
    "        d.update(f)\n",
    "        for k in d:\n",
    "            setattr(self, k, d[k])\n",
    "\n",
    "    def pop(self, k, d=None):\n",
    "        delattr(self, k)\n",
    "        return super(EasyDict, self).pop(k, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(cfg):\n",
    "    def get_object(transform):\n",
    "        if hasattr(album, transform.name):\n",
    "            return getattr(album, transform.name)\n",
    "        else:\n",
    "            return eval(transform.name)\n",
    "    if cfg['transforms']:\n",
    "        transforms = [get_object(transform)(**transform.params) for name, transform in cfg['transforms'].items()]\n",
    "        return album.Compose(transforms)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def concat_tiles(image_list, seed):\n",
    "    random.seed(seed)\n",
    "    random.shuffle(image_list)\n",
    "\n",
    "    image = cv2.hconcat([\n",
    "        cv2.vconcat([image_list[0], image_list[1], image_list[2], image_list[3]]), \n",
    "        cv2.vconcat([image_list[4], image_list[5], image_list[6], image_list[7]]), \n",
    "        cv2.vconcat([image_list[8], image_list[9], image_list[10], image_list[11]]), \n",
    "        cv2.vconcat([image_list[12], image_list[13], image_list[14], image_list[15]])\n",
    "    ])\n",
    "    return image\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, labels, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.image_ids = df['image_id'].values\n",
    "        self.labels = labels\n",
    "        self.transforms = get_transforms(self.cfg)\n",
    "        self.is_train = cfg.is_train\n",
    "        self.img_type = cfg.img_type\n",
    "        if self.img_type == 'image':\n",
    "            self.image_path = '/kaggle/test_images'\n",
    "        elif self.img_type == 'tile':\n",
    "            self.image_path = '/kaggle/test_tile_images'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        if self.img_type == 'image':\n",
    "            image = cv2.imread(f'{self.image_path}/{image_id}.png')\n",
    "        elif self.img_type == 'tile':\n",
    "            tiles = []\n",
    "            for i in range(16):\n",
    "                tiles.append(cv2.imread(f'{self.image_path}/{image_id}_{i}.png'))\n",
    "            image = concat_tiles(tiles, idx)\n",
    "        image = 255 - (image * (255.0/image.max())).astype(np.uint8)\n",
    "        image = cv2.resize(image, dsize=(self.cfg.img_size.height, self.cfg.img_size.width))\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        image = image.transpose(2, 0, 1).astype(np.float32)\n",
    "\n",
    "        if self.is_train:\n",
    "            label = self.labels.values[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, x.shape[2:])\n",
    "\n",
    "\n",
    "class MaxPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.max_pool2d(x, x.shape[2:])\n",
    "\n",
    "\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/c/bengaliai-cv19/discussion/123432\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "    \n",
    "    \n",
    "layer_encoder = {\n",
    "    'AvgPool': AvgPool,\n",
    "    'MaxPool': MaxPool,\n",
    "    'AdaptiveConcatPool2d': AdaptiveConcatPool2d,\n",
    "    'GeM': GeM,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Regression\n",
    "# =============================================================================\n",
    "class MSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return self.mse(yhat,y)\n",
    "\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Classification\n",
    "# =============================================================================\n",
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.xloss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return self.xloss(yhat,y)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/55681502/label-smoothing-in-pytorch\n",
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth_one_hot(targets:torch.Tensor, n_classes:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = torch.empty(size=(targets.size(0), n_classes),\n",
    "                    device=targets.device) \\\n",
    "                .fill_(smoothing /(n_classes-1)) \\\n",
    "                .scatter_(1, targets.data.unsqueeze(1), 1.-smoothing)\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss._smooth_one_hot(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        lsm = F.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            lsm = lsm * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = -(targets * lsm).sum(-1)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "# https://kyudy.hatenablog.com/entry/2019/05/20/105526\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, eps=1e-7):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        logit = F.softmax(input, dim=1)\n",
    "        logit = logit.clamp(self.eps, 1. - self.eps)\n",
    "        logit_ls = torch.log(logit)\n",
    "        loss = F.nll_loss(logit_ls, target, reduction=\"none\")\n",
    "        view = target.size() + (1,)\n",
    "        index = target.view(*view)\n",
    "        loss = loss * (1 - logit.gather(1, index).squeeze(1)) ** self.gamma # focal loss\n",
    "\n",
    "        return loss.sum()\n",
    "\n",
    "\n",
    "# https://github.com/vandit15/Class-balanced-loss-pytorch/blob/master/class_balanced_loss.py\n",
    "def focal_loss(labels, logits, alpha, gamma):\n",
    "    \"\"\"Compute the focal loss between `logits` and the ground truth `labels`.\n",
    "    Focal loss = -alpha_t * (1-pt)^gamma * log(pt)\n",
    "    where pt is the probability of being classified to the true class.\n",
    "    pt = p (if true class), otherwise pt = 1 - p. p = sigmoid(logit).\n",
    "    Args:\n",
    "      labels: A float tensor of size [batch, num_classes].\n",
    "      logits: A float tensor of size [batch, num_classes].\n",
    "      alpha: A float tensor of size [batch_size]\n",
    "        specifying per-example weight for balanced cross entropy.\n",
    "      gamma: A float scalar modulating loss from hard and easy examples.\n",
    "    Returns:\n",
    "      focal_loss: A float32 scalar representing normalized total loss.\n",
    "    \"\"\"    \n",
    "    BCLoss = F.binary_cross_entropy_with_logits(input = logits, target = labels,reduction = \"none\")\n",
    "\n",
    "    if gamma == 0.0:\n",
    "        modulator = 1.0\n",
    "    else:\n",
    "        modulator = torch.exp(-gamma * labels * logits - gamma * torch.log(1 + \n",
    "            torch.exp(-1.0 * logits)))\n",
    "\n",
    "    loss = modulator * BCLoss\n",
    "\n",
    "    weighted_loss = alpha * loss\n",
    "    focal_loss = torch.sum(weighted_loss)\n",
    "\n",
    "    focal_loss /= torch.sum(labels)\n",
    "    return focal_loss\n",
    "\n",
    "\n",
    "class ClassBalancedLoss(nn.Module):\n",
    "    def __init__(self, samples_per_cls, no_of_classes, loss_type, beta, gamma):\n",
    "        \"\"\"Compute the Class Balanced Loss between `logits` and the ground truth `labels`.\n",
    "        Class Balanced Loss: ((1-beta)/(1-beta^n))*Loss(labels, logits)\n",
    "        where Loss is one of the standard losses used for Neural Networks.\n",
    "        Args:\n",
    "        labels: A int tensor of size [batch].\n",
    "        logits: A float tensor of size [batch, no_of_classes].\n",
    "        samples_per_cls: A python list of size [no_of_classes].\n",
    "        no_of_classes: total number of classes. int\n",
    "        loss_type: string. One of \"sigmoid\", \"focal\", \"softmax\".\n",
    "        beta: float. Hyperparameter for Class balanced loss.\n",
    "        gamma: float. Hyperparameter for Focal loss.\n",
    "        Returns:\n",
    "        cb_loss: A float tensor representing class balanced loss\n",
    "        \"\"\"\n",
    "        super(ClassBalancedLoss, self).__init__()\n",
    "        self.samples_per_cls = samples_per_cls\n",
    "        self.no_of_classes = no_of_classes\n",
    "        self.loss_type = loss_type\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        effective_num = 1.0 - torch.pow(self.beta, self.samples_per_cls)\n",
    "        weights = (1.0 - self.beta) / torch.tensor(effective_num)\n",
    "        weights = weights / torch.sum(weights) * self.no_of_classes\n",
    "\n",
    "        labels_one_hot = F.one_hot(labels, self.no_of_classes).float()\n",
    "\n",
    "        weights = torch.tensor(weights).float()\n",
    "        weights = weights.unsqueeze(0)\n",
    "        weights = weights.repeat(labels_one_hot.shape[0],1) * labels_one_hot\n",
    "        weights = weights.sum(1)\n",
    "        weights = weights.unsqueeze(1)\n",
    "        weights = weights.repeat(1,self.no_of_classes)\n",
    "\n",
    "        if self.loss_type == \"focal\":\n",
    "            cb_loss = focal_loss(labels_one_hot, logits, weights, self.gamma)\n",
    "        elif self.loss_type == \"sigmoid\":\n",
    "            cb_loss = F.binary_cross_entropy_with_logits(input = logits,target = labels_one_hot, weights = weights)\n",
    "        elif self.loss_type == \"softmax\":\n",
    "            pred = logits.softmax(dim = 1)\n",
    "            cb_loss = F.binary_cross_entropy(input = pred, target = labels_one_hot, weight = weights)\n",
    "        return cb_loss\n",
    "\n",
    "\n",
    "class OhemLoss(nn.Module):\n",
    "    def __init__(self, rate=0.8):\n",
    "        super(OhemLoss, self).__init__()\n",
    "        self.rate = rate\n",
    "\n",
    "    def update_rate(self, rate):\n",
    "        self.rate = rate\n",
    "        \n",
    "    def forward(self, cls_pred, cls_target):\n",
    "        batch_size = cls_pred.size(0) \n",
    "        ohem_cls_loss = F.cross_entropy(cls_pred, cls_target, reduction='none', ignore_index=-1)\n",
    "\n",
    "        sorted_ohem_loss, idx = torch.sort(ohem_cls_loss, descending=True)\n",
    "        keep_num = min(sorted_ohem_loss.size()[0], int(batch_size*self.rate) )\n",
    "        if keep_num < sorted_ohem_loss.size()[0]:\n",
    "            keep_idx_cuda = idx[:keep_num]\n",
    "            ohem_cls_loss = ohem_cls_loss[keep_idx_cuda]\n",
    "        cls_loss = ohem_cls_loss.sum() / keep_num\n",
    "        return cls_loss\n",
    "    \n",
    "    \n",
    "loss_encoder = {\n",
    "    'MSELoss': MSELoss,\n",
    "    'RMSELoss': RMSELoss,\n",
    "    'CrossEntropyLoss': CrossEntropyLoss,\n",
    "    'SmoothCrossEntropyLoss': SmoothCrossEntropyLoss,\n",
    "    'FocalLoss': FocalLoss,\n",
    "    'ClassBalancedLoss': ClassBalancedLoss,\n",
    "    'OhemLoss': OhemLoss\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/zhanghang1989/ResNeSt/blob/master/resnest/torch/splat.py\n",
    "class SplAtConv2d(Module):\n",
    "    \"\"\"Split-Attention Conv2d\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, channels, kernel_size, stride=(1, 1), padding=(0, 0),\n",
    "                 dilation=(1, 1), groups=1, bias=True,\n",
    "                 radix=2, reduction_factor=4,\n",
    "                 rectify=False, rectify_avg=False, norm_layer=None,\n",
    "                 dropblock_prob=0.0, **kwargs):\n",
    "        super(SplAtConv2d, self).__init__()\n",
    "        padding = _pair(padding)\n",
    "        self.rectify = rectify and (padding[0] > 0 or padding[1] > 0)\n",
    "        self.rectify_avg = rectify_avg\n",
    "        inter_channels = max(in_channels*radix//reduction_factor, 32)\n",
    "        self.radix = radix\n",
    "        self.cardinality = groups\n",
    "        self.channels = channels\n",
    "        self.dropblock_prob = dropblock_prob\n",
    "        if self.rectify:\n",
    "            from rfconv import RFConv2d\n",
    "            self.conv = RFConv2d(in_channels, channels*radix, kernel_size, stride, padding, dilation,\n",
    "                                 groups=groups*radix, bias=bias, average_mode=rectify_avg, **kwargs)\n",
    "        else:\n",
    "            self.conv = Conv2d(in_channels, channels*radix, kernel_size, stride, padding, dilation,\n",
    "                               groups=groups*radix, bias=bias, **kwargs)\n",
    "        self.use_bn = norm_layer is not None\n",
    "        if self.use_bn:\n",
    "            self.bn0 = norm_layer(channels*radix)\n",
    "        self.relu = ReLU(inplace=True)\n",
    "        self.fc1 = Conv2d(channels, inter_channels, 1, groups=self.cardinality)\n",
    "        if self.use_bn:\n",
    "            self.bn1 = norm_layer(inter_channels)\n",
    "        self.fc2 = Conv2d(inter_channels, channels*radix, 1, groups=self.cardinality)\n",
    "        if dropblock_prob > 0.0:\n",
    "            self.dropblock = DropBlock2D(dropblock_prob, 3)\n",
    "        self.rsoftmax = rSoftMax(radix, groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn0(x)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            x = self.dropblock(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        batch, rchannel = x.shape[:2]\n",
    "        if self.radix > 1:\n",
    "            splited = torch.split(x, rchannel//self.radix, dim=1)\n",
    "            gap = sum(splited) \n",
    "        else:\n",
    "            gap = x\n",
    "        gap = F.adaptive_avg_pool2d(gap, 1)\n",
    "        gap = self.fc1(gap)\n",
    "\n",
    "        if self.use_bn:\n",
    "            gap = self.bn1(gap)\n",
    "        gap = self.relu(gap)\n",
    "\n",
    "        atten = self.fc2(gap)\n",
    "        atten = self.rsoftmax(atten).view(batch, -1, 1, 1)\n",
    "\n",
    "        if self.radix > 1:\n",
    "            attens = torch.split(atten, rchannel//self.radix, dim=1)\n",
    "            out = sum([att*split for (att, split) in zip(attens, splited)])\n",
    "        else:\n",
    "            out = atten * x\n",
    "        return out.contiguous()\n",
    "\n",
    "class rSoftMax(nn.Module):\n",
    "    def __init__(self, radix, cardinality):\n",
    "        super().__init__()\n",
    "        self.radix = radix\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.size(0)\n",
    "        if self.radix > 1:\n",
    "            x = x.view(batch, self.cardinality, self.radix, -1).transpose(1, 2)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            x = x.reshape(batch, -1)\n",
    "        else:\n",
    "            x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "_url_format = 'https://hangzh.s3.amazonaws.com/encoding/models/{}-{}.pth'\n",
    "\n",
    "_model_sha256 = {name: checksum for checksum, name in [\n",
    "    ('528c19ca', 'resnest50'),\n",
    "    ('22405ba7', 'resnest101'),\n",
    "    ('75117900', 'resnest200'),\n",
    "    ('0cc87c48', 'resnest269'),\n",
    "    ]}\n",
    "\n",
    "\n",
    "class DropBlock2D(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Global average pooling over the input's spatial dimensions\"\"\"\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return nn.functional.adaptive_avg_pool2d(inputs, 1).view(inputs.size(0), -1)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet Bottleneck\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-argument\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 radix=1, cardinality=1, bottleneck_width=64,\n",
    "                 avd=False, avd_first=False, dilation=1, is_first=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 norm_layer=None, dropblock_prob=0.0, last_gamma=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        group_width = int(planes * (bottleneck_width / 64.)) * cardinality\n",
    "        self.conv1 = nn.Conv2d(inplanes, group_width, kernel_size=1, bias=False)\n",
    "        self.bn1 = norm_layer(group_width)\n",
    "        self.dropblock_prob = dropblock_prob\n",
    "        self.radix = radix\n",
    "        self.avd = avd and (stride > 1 or is_first)\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        if self.avd:\n",
    "            self.avd_layer = nn.AvgPool2d(3, stride, padding=1)\n",
    "            stride = 1\n",
    "\n",
    "        if dropblock_prob > 0.0:\n",
    "            self.dropblock1 = DropBlock2D(dropblock_prob, 3)\n",
    "            if radix == 1:\n",
    "                self.dropblock2 = DropBlock2D(dropblock_prob, 3)\n",
    "            self.dropblock3 = DropBlock2D(dropblock_prob, 3)\n",
    "\n",
    "        if radix >= 1:\n",
    "            self.conv2 = SplAtConv2d(\n",
    "                group_width, group_width, kernel_size=3,\n",
    "                stride=stride, padding=dilation,\n",
    "                dilation=dilation, groups=cardinality, bias=False,\n",
    "                radix=radix, rectify=rectified_conv,\n",
    "                rectify_avg=rectify_avg,\n",
    "                norm_layer=norm_layer,\n",
    "                dropblock_prob=dropblock_prob)\n",
    "        elif rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            self.conv2 = RFConv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False,\n",
    "                average_mode=rectify_avg)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "        else:\n",
    "            self.conv2 = nn.Conv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            group_width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = norm_layer(planes*4)\n",
    "\n",
    "        if last_gamma:\n",
    "            from torch.nn.init import zeros_\n",
    "            zeros_(self.bn3.weight)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.avd and self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        if self.radix == 0:\n",
    "            out = self.bn2(out)\n",
    "            if self.dropblock_prob > 0.0:\n",
    "                out = self.dropblock2(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "        if self.avd and not self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"ResNet Variants\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : Block\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    dilated : bool, default False\n",
    "        Applying dilation strategy to pretrained ResNet yielding a stride-8 model,\n",
    "        typically used in Semantic Segmentation.\n",
    "    norm_layer : object\n",
    "        Normalization layer used in backbone network (default: :class:`mxnet.gluon.nn.BatchNorm`;\n",
    "        for Synchronized Cross-GPU BachNormalization).\n",
    "    Reference:\n",
    "        - He, Kaiming, et al. \"Deep residual learning for image recognition.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n",
    "        - Yu, Fisher, and Vladlen Koltun. \"Multi-scale context aggregation by dilated convolutions.\"\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-variable\n",
    "    def __init__(self, block, layers, radix=1, groups=1, bottleneck_width=64,\n",
    "                 num_classes=1000, dilated=False, dilation=1,\n",
    "                 deep_stem=False, stem_width=64, avg_down=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 avd=False, avd_first=False,\n",
    "                 final_drop=0.0, dropblock_prob=0,\n",
    "                 last_gamma=False, norm_layer=nn.BatchNorm2d):\n",
    "        self.cardinality = groups\n",
    "        self.bottleneck_width = bottleneck_width\n",
    "        # ResNet-D params\n",
    "        self.inplanes = stem_width*2 if deep_stem else 64\n",
    "        self.avg_down = avg_down\n",
    "        self.last_gamma = last_gamma\n",
    "        # ResNeSt params\n",
    "        self.radix = radix\n",
    "        self.avd = avd\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "        self.rectified_conv = rectified_conv\n",
    "        self.rectify_avg = rectify_avg\n",
    "        if rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            conv_layer = RFConv2d\n",
    "        else:\n",
    "            conv_layer = nn.Conv2d\n",
    "        conv_kwargs = {'average_mode': rectify_avg} if rectified_conv else {}\n",
    "        if deep_stem:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                conv_layer(3, stem_width, kernel_size=3, stride=2, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width*2, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = conv_layer(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                   bias=False, **conv_kwargs)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], norm_layer=norm_layer, is_first=False)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, norm_layer=norm_layer)\n",
    "        if dilated or dilation == 4:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=4, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        elif dilation==2:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           dilation=1, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        else:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        self.avgpool = GlobalAvgPool2d()\n",
    "        self.drop = nn.Dropout(final_drop) if final_drop > 0.0 else None\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, norm_layer):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, norm_layer=None,\n",
    "                    dropblock_prob=0.0, is_first=True):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            down_layers = []\n",
    "            if self.avg_down:\n",
    "                if dilation == 1:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=stride, stride=stride,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                else:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=1, stride=1,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=1, bias=False))\n",
    "            else:\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=stride, bias=False))\n",
    "            down_layers.append(norm_layer(planes * block.expansion))\n",
    "            downsample = nn.Sequential(*down_layers)\n",
    "\n",
    "        layers = []\n",
    "        if dilation == 1 or dilation == 2:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=1, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        elif dilation == 4:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=2, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        else:\n",
    "            raise RuntimeError(\"=> unknown dilation size: {}\".format(dilation))\n",
    "\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=dilation, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        if self.drop:\n",
    "            x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# https://github.com/zhanghang1989/ResNeSt/blob/master/resnest/torch/resnest.py\n",
    "def short_hash(name):\n",
    "    if name not in _model_sha256:\n",
    "        raise ValueError('Pretrained model for {name} is not available.'.format(name=name))\n",
    "    return _model_sha256[name][:8]\n",
    "\n",
    "resnest_model_urls = {name: _url_format.format(name, short_hash(name)) for\n",
    "    name in _model_sha256.keys()\n",
    "}\n",
    "\n",
    "\n",
    "def resnest50(pretrained=False, root='~/.encoding/models', **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3],\n",
    "                   radix=2, groups=1, bottleneck_width=64,\n",
    "                   deep_stem=True, stem_width=32, avg_down=True,\n",
    "                   avd=True, avd_first=False, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(torch.hub.load_state_dict_from_url(\n",
    "            resnest_model_urls['resnest50'], progress=True, check_hash=True))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnest101(pretrained=False, root='~/.encoding/models', **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3],\n",
    "                   radix=2, groups=1, bottleneck_width=64,\n",
    "                   deep_stem=True, stem_width=64, avg_down=True,\n",
    "                   avd=True, avd_first=False, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(torch.hub.load_state_dict_from_url(\n",
    "            resnest_model_urls['resnest101'], progress=True, check_hash=True))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnest200(pretrained=False, root='~/.encoding/models', **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 24, 36, 3],\n",
    "                   radix=2, groups=1, bottleneck_width=64,\n",
    "                   deep_stem=True, stem_width=64, avg_down=True,\n",
    "                   avd=True, avd_first=False, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(torch.hub.load_state_dict_from_url(\n",
    "            resnest_model_urls['resnest200'], progress=True, check_hash=True))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnest269(pretrained=False, root='~/.encoding/models', **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 30, 48, 8],\n",
    "                   radix=2, groups=1, bottleneck_width=64,\n",
    "                   deep_stem=True, stem_width=64, avg_down=True,\n",
    "                   avd=True, avd_first=False, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(torch.hub.load_state_dict_from_url(\n",
    "            resnest_model_urls['resnest269'], progress=True, check_hash=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder = {\n",
    "    'resnest50': resnest50,\n",
    "    'resnest101': resnest101,\n",
    "    'resnest200': resnest200,\n",
    "    'resnest269': resnest269,\n",
    "}\n",
    "\n",
    "\n",
    "def set_channels(child, cfg):\n",
    "    if cfg.model.n_channels < 3:\n",
    "        child_weight = child.weight.data[:, :cfg.model.n_channels, :, :]\n",
    "    else:\n",
    "        child_weight = torch.cat([child.weight.data[:, :, :, :], child.weight.data[:, :int(cfg.model.n_channels - 3), :, :]], dim=1)\n",
    "    setattr(child, 'in_channels', cfg.model.n_channels)\n",
    "\n",
    "    if cfg.model.pretrained:\n",
    "        setattr(child.weight, 'data', child_weight)\n",
    "\n",
    "\n",
    "def replace_channels(model, cfg):\n",
    "    if cfg.model.name.startswith('densenet'):\n",
    "        set_channels(model.features[0], cfg)\n",
    "    elif cfg.model.name.startswith('efficientnet'):\n",
    "        set_channels(model._conv_stem, cfg)\n",
    "    elif cfg.model.name.startswith('mobilenet'):\n",
    "        set_channels(model.features[0][0], cfg)\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        set_channels(model.layer0.conv1, cfg)\n",
    "    elif cfg.model.name.startswith('resnet') or cfg.model.name.startswith('resnex') or cfg.model.name.startswith('wide_resnet'):\n",
    "        set_channels(model.conv1, cfg)\n",
    "    elif cfg.model.name.startswith('resnest'):\n",
    "        set_channels(model.conv1[0], cfg)\n",
    "\n",
    "\n",
    "def replace_fc(model, cfg):\n",
    "    if cfg.model.metric:\n",
    "        classes = 1000\n",
    "    else:\n",
    "        classes = cfg.model.n_classes\n",
    "\n",
    "    if cfg.model.name.startswith('densenet'):\n",
    "        fc_input = getattr(model.classifier, 'in_features')\n",
    "        model.classifier = nn.Linear(fc_input, classes)\n",
    "    elif cfg.model.name.startswith('efficientnet'):\n",
    "        fc_input = getattr(model._fc, 'in_features')\n",
    "        model._fc = nn.Linear(fc_input, classes)\n",
    "    elif cfg.model.name.startswith('mobilenet'):\n",
    "        fc_input = getattr(model.classifier[1], 'in_features')\n",
    "        model.classifier[1] = nn.Linear(fc_input, classes)\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        fc_input = getattr(model.last_linear, 'in_features')\n",
    "        model.last_linear = nn.Linear(fc_input, classes)\n",
    "    elif cfg.model.name.startswith('resnet') or cfg.model.name.startswith('resnex') or cfg.model.name.startswith('wide_resnet') or cfg.model.name.startswith('resnest'):\n",
    "        fc_input = getattr(model.fc, 'in_features')\n",
    "        model.fc = nn.Linear(fc_input, classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def replace_pool(model, cfg):\n",
    "    avgpool = layer_encoder[cfg.model.avgpool.name](**cfg.model.avgpool.params)\n",
    "    if cfg.model.name.startswith('efficientnet'):\n",
    "        model._avg_pooling = avgpool\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        model.avg_pool = avgpool\n",
    "    elif cfg.model.name.startswith('resnet') or cfg.model.name.startswith('resnex') or cfg.model.name.startswith('wide_resnet') or cfg.model.name.startswith('resnest'):\n",
    "        model.avgpool = avgpool\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(cfg):\n",
    "    model = model_encoder[cfg.model.name](pretrained=False)\n",
    "    if cfg.model.n_channels != 3:\n",
    "        replace_channels(model, cfg)\n",
    "    model = replace_fc(model, cfg)\n",
    "    if cfg.model.avgpool:\n",
    "        model = replace_pool(model, cfg)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_loss(cfg):\n",
    "    loss_ = layer_encoder[cfg.loss.name](**cfg.loss.params)\n",
    "    return loss_\n",
    "\n",
    "\n",
    "def get_dataloader(df, labels, cfg):\n",
    "    dataset = CustomDataset(df, labels, cfg)\n",
    "    loader = DataLoader(dataset, **cfg.loader)\n",
    "    return loader\n",
    "\n",
    "\n",
    "def get_optim(cfg, parameters):\n",
    "    optim = getattr(torch.optim, cfg.optimizer.name)(params=parameters, **cfg.optimizer.params)\n",
    "    return optim\n",
    "\n",
    "\n",
    "def get_scheduler(cfg, optimizer):\n",
    "    if cfg.scheduler.name == 'ReduceLROnPlateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            **cfg.scheduler.params,\n",
    "        )\n",
    "    else:\n",
    "        scheduler = getattr(torch.optim.lr_scheduler, cfg.scheduler.name)(\n",
    "            optimizer,\n",
    "            **cfg.scheduler.params,\n",
    "        )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(y_hat, y):\n",
    "    return cohen_kappa_score(y_hat, y, weights='quadratic')\n",
    "\n",
    "\n",
    "class QWKOptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            elif pred >= coef[3] and pred < coef[4]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 5\n",
    "\n",
    "        ll = quadratic_weighted_kappa(y, X_p)\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(df, data_dir, save_dir):\n",
    "    for img_id in df['image_id']:\n",
    "        load_path = f'{data_dir}/{img_id}.tiff'\n",
    "        save_path = f'{save_dir}/{img_id}.png'\n",
    "            \n",
    "        biopsy = skimage.io.MultiImage(load_path)\n",
    "        img = cv2.resize(biopsy[-1], (512, 512))\n",
    "        cv2.imwrite(save_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  create_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile(img, sz=128, N=16):\n",
    "    result = []\n",
    "    shape = img.shape\n",
    "    pad0, pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n",
    "    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],\n",
    "                constant_values=255)\n",
    "    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n",
    "    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n",
    "    if len(img) < N:\n",
    "        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n",
    "    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n",
    "    img = img[idxs]\n",
    "    for i in range(len(img)):\n",
    "        result.append({'img':img[i], 'idx':i})\n",
    "    return result\n",
    "\n",
    "def create_tile(df, data_dir, save_dir):\n",
    "    x_tot,x2_tot = [],[]\n",
    "    for img_id in df['image_id']:\n",
    "        load_path = f'{data_dir}/{img_id}.tiff'\n",
    "        \n",
    "        img = skimage.io.MultiImage(load_path)[-1]\n",
    "        tiles = tile(img)\n",
    "        for t in tiles:\n",
    "            img, idx = t['img'],t['idx']\n",
    "#             x_tot.append((img/255.0).reshape(-1,3).mean(0))\n",
    "#             x2_tot.append(((img/255.0)**2).reshape(-1,3).mean(0))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            save_path = f'{save_dir}/{img_id}_{idx}.png'\n",
    "            cv2.imwrite(save_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(sample, data_dir, log_path):\n",
    "    if os.path.exists(data_dir):\n",
    "        print('run inference')\n",
    "        \n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        test_loader = get_dataloader(test_df, labels=None, cfg=cfg.data.test)\n",
    "        model = get_model(cfg).to(device)\n",
    "        model.load_state_dict(torch.load(log_path / 'weight_best.pt'))\n",
    "\n",
    "        all_preds = []\n",
    "        model.eval()\n",
    "        for images in test_loader:\n",
    "            images = Variable(images).to(device)\n",
    "\n",
    "            preds = model(images.float())\n",
    "            all_preds.append(preds.cpu().detach().numpy())\n",
    "        \n",
    "        if cfg.model.n_classes > 1:\n",
    "            preds_label = np.concatenate(all_preds).argmax(1)\n",
    "        else:\n",
    "            optR = QWKOptimizedRounder()\n",
    "            preds_label = optR.predict(np.concatenate(all_preds.copy()), best_coef)\n",
    "\n",
    "        sample['isup_grade'] = preds_label.astype(int)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/kaggle/input/prostate-cancer-grade-assessment/')\n",
    "log_path = Path(glob.glob('/kaggle/input/sub-*')[0])\n",
    "\n",
    "with open(log_path / 'config.yml', 'r') as yf:\n",
    "    cfg = EasyDict(yaml.safe_load(yf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(root / 'test.csv')\n",
    "data_dir = '/kaggle/input/prostate-cancer-grade-assessment/test_images'\n",
    "save_dir = '/kaggle/test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    test_df = pd.read_csv(root / 'train.csv').iloc[:3]\n",
    "    data_dir = '/kaggle/input/prostate-cancer-grade-assessment/train_images'\n",
    "\n",
    "if cfg.data.train.img_type == 'image':\n",
    "    resize(test_df, data_dir, save_dir)\n",
    "elif cfg.data.train.img_type == 'tile':\n",
    "    save_dir = '/kaggle/test_tile_images'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    create_tile(test_df, data_dir, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(root / 'sample_submission.csv')\n",
    "sample_df = submit(sample_df, data_dir, log_path)\n",
    "sample_df.to_csv('submission.csv', index=False)\n",
    "sample_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
