{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import skimage.io\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import albumentations as album\n",
    "\n",
    "sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master')\n",
    "from efficientnet_pytorch import model as enet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EasyDict(dict):\n",
    "    \"\"\"\n",
    "    Get attributes\n",
    "    >>> d = EasyDict({'foo':3})\n",
    "    >>> d['foo']\n",
    "    3\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    AttributeError: 'EasyDict' object has no attribute 'bar'\n",
    "    Works recursively\n",
    "    >>> d = EasyDict({'foo':3, 'bar':{'x':1, 'y':2}})\n",
    "    >>> isinstance(d.bar, dict)\n",
    "    True\n",
    "    >>> d.bar.x\n",
    "    1\n",
    "    Bullet-proof\n",
    "    >>> EasyDict({})\n",
    "    {}\n",
    "    >>> EasyDict(d={})\n",
    "    {}\n",
    "    >>> EasyDict(None)\n",
    "    {}\n",
    "    >>> d = {'a': 1}\n",
    "    >>> EasyDict(**d)\n",
    "    {'a': 1}\n",
    "    Set attributes\n",
    "    >>> d = EasyDict()\n",
    "    >>> d.foo = 3\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar = {'prop': 'value'}\n",
    "    >>> d.bar.prop\n",
    "    'value'\n",
    "    >>> d\n",
    "    {'foo': 3, 'bar': {'prop': 'value'}}\n",
    "    >>> d.bar.prop = 'newer'\n",
    "    >>> d.bar.prop\n",
    "    'newer'\n",
    "    Values extraction\n",
    "    >>> d = EasyDict({'foo':0, 'bar':[{'x':1, 'y':2}, {'x':3, 'y':4}]})\n",
    "    >>> isinstance(d.bar, list)\n",
    "    True\n",
    "    >>> from operator import attrgetter\n",
    "    >>> map(attrgetter('x'), d.bar)\n",
    "    [1, 3]\n",
    "    >>> map(attrgetter('y'), d.bar)\n",
    "    [2, 4]\n",
    "    >>> d = EasyDict()\n",
    "    >>> d.keys()\n",
    "    []\n",
    "    >>> d = EasyDict(foo=3, bar=dict(x=1, y=2))\n",
    "    >>> d.foo\n",
    "    3\n",
    "    >>> d.bar.x\n",
    "    1\n",
    "    Still like a dict though\n",
    "    >>> o = EasyDict({'clean':True})\n",
    "    >>> o.items()\n",
    "    [('clean', True)]\n",
    "    And like a class\n",
    "    >>> class Flower(EasyDict):\n",
    "    ...     power = 1\n",
    "    ...\n",
    "    >>> f = Flower()\n",
    "    >>> f.power\n",
    "    1\n",
    "    >>> f = Flower({'height': 12})\n",
    "    >>> f.height\n",
    "    12\n",
    "    >>> f['power']\n",
    "    1\n",
    "    >>> sorted(f.keys())\n",
    "    ['height', 'power']\n",
    "    update and pop items\n",
    "    >>> d = EasyDict(a=1, b='2')\n",
    "    >>> e = EasyDict(c=3.0, a=9.0)\n",
    "    >>> d.update(e)\n",
    "    >>> d.c\n",
    "    3.0\n",
    "    >>> d['c']\n",
    "    3.0\n",
    "    >>> d.get('c')\n",
    "    3.0\n",
    "    >>> d.update(a=4, b=4)\n",
    "    >>> d.b\n",
    "    4\n",
    "    >>> d.pop('a')\n",
    "    4\n",
    "    >>> d.a\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    AttributeError: 'EasyDict' object has no attribute 'a'\n",
    "    \"\"\"\n",
    "    def __init__(self, d=None, **kwargs):\n",
    "        if d is None:\n",
    "            d = {}\n",
    "        if kwargs:\n",
    "            d.update(**kwargs)\n",
    "        for k, v in d.items():\n",
    "            setattr(self, k, v)\n",
    "        # Class attributes\n",
    "        for k in self.__class__.__dict__.keys():\n",
    "            if not (k.startswith('__') and k.endswith('__')) and not k in ('update', 'pop'):\n",
    "                setattr(self, k, getattr(self, k))\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, (list, tuple)):\n",
    "            value = [self.__class__(x)\n",
    "                     if isinstance(x, dict) else x for x in value]\n",
    "        elif isinstance(value, dict) and not isinstance(value, self.__class__):\n",
    "            value = self.__class__(value)\n",
    "        super(EasyDict, self).__setattr__(name, value)\n",
    "        super(EasyDict, self).__setitem__(name, value)\n",
    "\n",
    "    __setitem__ = __setattr__\n",
    "\n",
    "    def update(self, e=None, **f):\n",
    "        d = e or dict()\n",
    "        d.update(f)\n",
    "        for k in d:\n",
    "            setattr(self, k, d[k])\n",
    "\n",
    "    def pop(self, k, d=None):\n",
    "        delattr(self, k)\n",
    "        return super(EasyDict, self).pop(k, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(cfg):\n",
    "    def get_object(transform):\n",
    "        if hasattr(album, transform.name):\n",
    "            return getattr(album, transform.name)\n",
    "        else:\n",
    "            return eval(transform.name)\n",
    "    if cfg['transforms']:\n",
    "        transforms = [get_object(transform)(**transform.params) for name, transform in cfg['transforms'].items()]\n",
    "        return album.Compose(transforms)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, labels, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.image_ids = df['image_id'].values\n",
    "        self.labels = labels\n",
    "        self.transforms = get_transforms(self.cfg)\n",
    "        self.is_train = cfg.is_train\n",
    "        self.image_path = '/kaggle/test_images'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = cv2.imread(f'{self.image_path}/{image_id}.png')\n",
    "        image = 255 - (image * (255.0/image.max())).astype(np.uint8)\n",
    "        image = cv2.resize(image, dsize=(self.cfg.img_size.height, self.cfg.img_size.width))\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        image = image.transpose(2, 0, 1).astype(np.float32)\n",
    "\n",
    "        if self.is_train:\n",
    "            label = self.labels[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, x.shape[2:])\n",
    "\n",
    "\n",
    "class MaxPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.max_pool2d(x, x.shape[2:])\n",
    "\n",
    "\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/c/bengaliai-cv19/discussion/123432\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "    \n",
    "    \n",
    "layer_encoder = {\n",
    "    'AvgPool': AvgPool,\n",
    "    'MaxPool': MaxPool,\n",
    "    'AdaptiveConcatPool2d': AdaptiveConcatPool2d,\n",
    "    'GeM': GeM,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _efficientnet(model_name, pretrained):\n",
    "    if pretrained:\n",
    "        model = enet.EfficientNet.from_pretrained(model_name, advprop=True)\n",
    "    else:\n",
    "        model = enet.EfficientNet.from_name(model_name)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def efficientnet_b0(model_name='efficientnet-b0', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b1(model_name='efficientnet-b1', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b2(model_name='efficientnet-b2', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b3(model_name='efficientnet-b3', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b4(model_name='efficientnet-b4', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b5(model_name='efficientnet-b5', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b6(model_name='efficientnet-b6', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)\n",
    "\n",
    "\n",
    "def efficientnet_b7(model_name='efficientnet-b7', pretrained=False):\n",
    "    return _efficientnet(model_name, pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder = {\n",
    "    'efficientnet_b0': efficientnet_b0,\n",
    "    'efficientnet_b1': efficientnet_b1,\n",
    "    'efficientnet_b2': efficientnet_b2,\n",
    "    'efficientnet_b3': efficientnet_b3,\n",
    "    'efficientnet_b4': efficientnet_b4,\n",
    "    'efficientnet_b5': efficientnet_b5,\n",
    "    'efficientnet_b6': efficientnet_b6,\n",
    "    'efficientnet_b7': efficientnet_b7,\n",
    "}\n",
    "\n",
    "\n",
    "def set_channels(child, cfg):\n",
    "    if cfg.model.n_channels < 3:\n",
    "        child_weight = child.weight.data[:, :cfg.model.n_channels, :, :]\n",
    "    else:\n",
    "        child_weight = torch.cat([child.weight.data[:, :, :, :], child.weight.data[:, :int(cfg.model.n_channels - 3), :, :]], dim=1)\n",
    "    setattr(child, 'in_channels', cfg.model.n_channels)\n",
    "\n",
    "    if cfg.model.pretrained:\n",
    "        setattr(child.weight, 'data', child_weight)\n",
    "\n",
    "\n",
    "def replace_channels(model, cfg):\n",
    "    if cfg.model.name.startswith('densenet'):\n",
    "        set_channels(model.features[0], cfg)\n",
    "    elif cfg.model.name.startswith('efficientnet'):\n",
    "        set_channels(model._conv_stem, cfg)\n",
    "    elif cfg.model.name.startswith('mobilenet'):\n",
    "        set_channels(model.features[0][0], cfg)\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        set_channels(model.layer0.conv1, cfg)\n",
    "    elif cfg.model.name.startswith('resnet') or cfg.model.name.startswith('resnex') or cfg.model.name.startswith('wide_resnet'):\n",
    "        set_channels(model.conv1, cfg)\n",
    "    elif cfg.model.name.startswith('resnest'):\n",
    "        set_channels(model.conv1[0], cfg)\n",
    "\n",
    "\n",
    "def replace_fc(model, cfg):\n",
    "    if cfg.model.metric:\n",
    "        classes = 1000\n",
    "    else:\n",
    "        classes = cfg.model.n_classes\n",
    "\n",
    "    if cfg.model.name.startswith('densenet'):\n",
    "        fc_input = getattr(model.classifier, 'in_features')\n",
    "        model.classifier = nn.Linear(fc_input, classes)\n",
    "    elif cfg.model.name.startswith('efficientnet'):\n",
    "        fc_input = getattr(model._fc, 'in_features')\n",
    "        model._fc = nn.Linear(fc_input, classes)\n",
    "    elif cfg.model.name.startswith('mobilenet'):\n",
    "        fc_input = getattr(model.classifier[1], 'in_features')\n",
    "        model.classifier[1] = nn.Linear(fc_input, classes)\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        fc_input = getattr(model.last_linear, 'in_features')\n",
    "        model.last_linear = nn.Linear(fc_input, classes)\n",
    "    elif cfg.model.name.startswith('resnet') or cfg.model.name.startswith('resnex') or cfg.model.name.startswith('wide_resnet') or cfg.model.name.startswith('resnest'):\n",
    "        fc_input = getattr(model.fc, 'in_features')\n",
    "        model.fc = nn.Linear(fc_input, classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def replace_pool(model, cfg):\n",
    "    avgpool = layer_encoder[cfg.model.avgpool.name](**cfg.model.avgpool.params)\n",
    "    if cfg.model.name.startswith('efficientnet'):\n",
    "        model._avg_pooling = avgpool\n",
    "    elif cfg.model.name.startswith('se_resnext'):\n",
    "        model.avg_pool = avgpool\n",
    "    elif cfg.model.name.startswith('resnet') or cfg.model.name.startswith('resnex') or cfg.model.name.startswith('wide_resnet') or cfg.model.name.startswith('resnest'):\n",
    "        model.avgpool = avgpool\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(cfg):\n",
    "    model = model_encoder[cfg.model.name](pretrained=False)\n",
    "    if cfg.model.n_channels != 3:\n",
    "        replace_channels(model, cfg)\n",
    "    model = replace_fc(model, cfg)\n",
    "    if cfg.model.avgpool:\n",
    "        model = replace_pool(model, cfg)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_loss(cfg):\n",
    "    loss = getattr(nn, cfg.loss.name)(**cfg.loss.params)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def get_dataloader(df, labels, cfg):\n",
    "    dataset = CustomDataset(df, labels, cfg)\n",
    "    loader = DataLoader(dataset, **cfg.loader)\n",
    "    return loader\n",
    "\n",
    "\n",
    "def get_optim(cfg, parameters):\n",
    "    optim = getattr(torch.optim, cfg.optimizer.name)(params=parameters, **cfg.optimizer.params)\n",
    "    return optim\n",
    "\n",
    "\n",
    "def get_scheduler(cfg, optimizer):\n",
    "    if cfg.scheduler.name == 'ReduceLROnPlateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            **cfg.scheduler.params,\n",
    "        )\n",
    "    else:\n",
    "        scheduler = getattr(torch.optim.lr_scheduler, cfg.scheduler.name)(\n",
    "            optimizer,\n",
    "            **cfg.scheduler.params,\n",
    "        )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(y_hat, y):\n",
    "    return cohen_kappa_score(y_hat, y, weights='quadratic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(df, data_dir, save_dir):\n",
    "    if os.path.exists(data_dir):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        for img_id in df['image_id']:\n",
    "            load_path = f'{data_dir}/{img_id}.tiff'\n",
    "            save_path = f'{save_dir}/{img_id}.png'\n",
    "            \n",
    "            biopsy = skimage.io.MultiImage(load_path)\n",
    "            img = cv2.resize(biopsy[-1], (512, 512))\n",
    "            cv2.imwrite(save_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(sample, data_dir, log_path):\n",
    "    if os.path.exists(data_dir):\n",
    "        print('run inference')\n",
    "        \n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        test_loader = get_dataloader(test_df, labels=None, cfg=cfg.data.test)\n",
    "        model = get_model(cfg).to(device)\n",
    "        model.load_state_dict(torch.load(log_path / 'weight_best.pt'))\n",
    "\n",
    "        all_preds = []\n",
    "        model.eval()\n",
    "        for images in test_loader:\n",
    "            images = Variable(images).to(device)\n",
    "\n",
    "            preds = model(images.float())\n",
    "            all_preds.append(preds.cpu().detach().numpy())\n",
    "\n",
    "        preds_label = np.concatenate(all_preds).argmax(1)\n",
    "        sample['isup_grade'] = preds_label.astype(int)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/kaggle/input/prostate-cancer-grade-assessment/')\n",
    "log_path = Path(glob.glob('/kaggle/input/sub-*')[0])\n",
    "\n",
    "test_df = pd.read_csv(root / 'test.csv')\n",
    "data_dir = '/kaggle/input/prostate-cancer-grade-assessment/test_images'\n",
    "save_dir = '/kaggle/test_images/'\n",
    "\n",
    "with open(log_path / 'config.yml', 'r') as yf:\n",
    "    cfg = EasyDict(yaml.safe_load(yf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize(test_df, data_dir, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(root / 'sample_submission.csv')\n",
    "sample_df = submit(sample_df, data_dir, log_path)\n",
    "sample_df.to_csv('submission.csv', index=False)\n",
    "sample_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
